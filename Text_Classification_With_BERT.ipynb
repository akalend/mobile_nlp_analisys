{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Text_Classification_With_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "50601d97b44947b6a53aeb8ae2c7a887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d0377b4d9df745389f1ea3367c83e590",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d02cb564c1d9417f9dcce52114ecc860",
              "IPY_MODEL_fa458a582fb346e2bd79ae195115fc08"
            ]
          }
        },
        "d0377b4d9df745389f1ea3367c83e590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d02cb564c1d9417f9dcce52114ecc860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3f8f7927f41c46418573c04db2f71541",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a712f4a8955f4278bf6cd02b4fc00734"
          }
        },
        "fa458a582fb346e2bd79ae195115fc08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b7d9a5c7661b4b35b744c2daf54aa40c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 2.47kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e34279673ff84a408aa1bdcdc6833856"
          }
        },
        "3f8f7927f41c46418573c04db2f71541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a712f4a8955f4278bf6cd02b4fc00734": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7d9a5c7661b4b35b744c2daf54aa40c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e34279673ff84a408aa1bdcdc6833856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd3d0c69b7a7472c889e963be7d8e4b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3eaa1b4f228f41d6ae392c90449302ab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_63eedafd52df412ab3f8a8e9a7b3436b",
              "IPY_MODEL_71f0bcb8bb2043aa84bc154beaca7998"
            ]
          }
        },
        "3eaa1b4f228f41d6ae392c90449302ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63eedafd52df412ab3f8a8e9a7b3436b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_11a1ecf903054d75af3d8197c7940803",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30c09f1cb4bd4e918aa449bd6347ef74"
          }
        },
        "71f0bcb8bb2043aa84bc154beaca7998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8a28702b7beb421dbf4188052eef5572",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:55&lt;00:00, 7.98MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_502cf7a52ef94626bafd07ed88eda00b"
          }
        },
        "11a1ecf903054d75af3d8197c7940803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30c09f1cb4bd4e918aa449bd6347ef74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a28702b7beb421dbf4188052eef5572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "502cf7a52ef94626bafd07ed88eda00b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4cbab7727543441ea8efaff9b68ba826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_af5c0bb49fb64307b24c40d8b8671f9a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9c7f93daadbe42599f7d8fe08c74f7c6",
              "IPY_MODEL_d33baed97d7e4a44985fc80029f68a9d"
            ]
          }
        },
        "af5c0bb49fb64307b24c40d8b8671f9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c7f93daadbe42599f7d8fe08c74f7c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a54dce671a774f86ab55085ed6ec2145",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3028a4c9519445268db17e06bc2a9f34"
          }
        },
        "d33baed97d7e4a44985fc80029f68a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c4693d3926ef42969d43448180d4496b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/4 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48237af598424b50a2e983dc6a25828c"
          }
        },
        "a54dce671a774f86ab55085ed6ec2145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3028a4c9519445268db17e06bc2a9f34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4693d3926ef42969d43448180d4496b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48237af598424b50a2e983dc6a25828c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b21991d701342bfb2451152f286b027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5d2b9b74312443f0ba9072afc19b4b58",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8f6ae9157713429daa987da26bf53c58",
              "IPY_MODEL_a427ad5f0f9e4af0a5e5716316eb0d52"
            ]
          }
        },
        "5d2b9b74312443f0ba9072afc19b4b58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f6ae9157713429daa987da26bf53c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7260ab1645624d18bdc6ca63c7277ed7",
            "_dom_classes": [],
            "description": "Epoch 1:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 268,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8955e608c0df44578a99fc7d6a6aafd1"
          }
        },
        "a427ad5f0f9e4af0a5e5716316eb0d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bbe88817865e41f3a7b59883c25041fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/268 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12b63526a3f0450f9c324ae50b636eaf"
          }
        },
        "7260ab1645624d18bdc6ca63c7277ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8955e608c0df44578a99fc7d6a6aafd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bbe88817865e41f3a7b59883c25041fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12b63526a3f0450f9c324ae50b636eaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akalend/mobile_nlp_analisys/blob/master/Text_Classification_With_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py5LLsuDUq82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcc752b-e546-4bcc-be2c-ad4926407f80"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 29.5MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 22.2MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 24.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 25.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 28.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 18.3MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 19.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 19.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 19.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 19.0MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 19.0MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 19.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 19.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 19.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 19.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 19.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 19.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 19.0MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 440kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 501kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 563kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 604kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 614kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 665kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 727kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 768kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 778kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 788kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 829kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 839kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 880kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 901kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911kB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 931kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 942kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 952kB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 962kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 993kB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0MB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0MB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2MB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 19.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3MB 19.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.3MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 19.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 19.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 51.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 39.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=cff4afb3913e4a3996c6b1bf24ad4c30980e273648b024e27fc370b6d4afc6c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7YwZ85aUi1t"
      },
      "source": [
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "from transformers import BertForSequenceClassification"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2bmSgsIReUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d426db7f-1818-4436-9396-fa37e7a1fdf1"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('russian')) \n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1FpRujbUi15"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "f = open('data/review.csv', 'r')\n",
        "in_text = []\n",
        "line = True\n",
        "while line:\n",
        "  line = f.readline()\n",
        "  if not line:\n",
        "    break\n",
        "  in_text.append(line)\n",
        "\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEgWzF6R8qxw"
      },
      "source": [
        "df = pd.DataFrame(in_text, columns=['comment'])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF53hVzNUi2G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "21992c5c-e402-4117-c840-f27a3858cbe3"
      },
      "source": [
        "df"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>На девятый день рождения дочка попросила новый...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Привет всем друзьям и посетителям Отзовика!Сма...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>За 10 000 рублей данный смартфон это оптимальн...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Привет, дорогой читатель(а может и пользовател...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Искал себе телефон небольших размеров, чтоб уд...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2584</th>\n",
              "      <td>Покупала телефон за 7500, сейчас он вышел из п...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2585</th>\n",
              "      <td>Покупал его новый за 4300 рублей. В нём мне оч...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2586</th>\n",
              "      <td>Пользуюсь смартфоном Fly IQ 441 уже больше год...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2587</th>\n",
              "      <td>Всем привет. Этот телефон мне очень понравился...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2588</th>\n",
              "      <td>Получила данный телефон в подарок от мужа на д...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2589 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                comment\n",
              "0     На девятый день рождения дочка попросила новый...\n",
              "1     Привет всем друзьям и посетителям Отзовика!Сма...\n",
              "2     За 10 000 рублей данный смартфон это оптимальн...\n",
              "3     Привет, дорогой читатель(а может и пользовател...\n",
              "4     Искал себе телефон небольших размеров, чтоб уд...\n",
              "...                                                 ...\n",
              "2584  Покупала телефон за 7500, сейчас он вышел из п...\n",
              "2585  Покупал его новый за 4300 рублей. В нём мне оч...\n",
              "2586  Пользуюсь смартфоном Fly IQ 441 уже больше год...\n",
              "2587  Всем привет. Этот телефон мне очень понравился...\n",
              "2588  Получила данный телефон в подарок от мужа на д...\n",
              "\n",
              "[2589 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSzoitdMV83t"
      },
      "source": [
        "df.drop_duplicates(subset=['comment'],inplace=True)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNQozFJZWl23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bdc31e5-8374-4bda-aa05-6c071c594188"
      },
      "source": [
        "stop_words"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'а',\n",
              " 'без',\n",
              " 'более',\n",
              " 'больше',\n",
              " 'будет',\n",
              " 'будто',\n",
              " 'бы',\n",
              " 'был',\n",
              " 'была',\n",
              " 'были',\n",
              " 'было',\n",
              " 'быть',\n",
              " 'в',\n",
              " 'вам',\n",
              " 'вас',\n",
              " 'вдруг',\n",
              " 'ведь',\n",
              " 'во',\n",
              " 'вот',\n",
              " 'впрочем',\n",
              " 'все',\n",
              " 'всегда',\n",
              " 'всего',\n",
              " 'всех',\n",
              " 'всю',\n",
              " 'вы',\n",
              " 'где',\n",
              " 'да',\n",
              " 'даже',\n",
              " 'два',\n",
              " 'для',\n",
              " 'до',\n",
              " 'другой',\n",
              " 'его',\n",
              " 'ее',\n",
              " 'ей',\n",
              " 'ему',\n",
              " 'если',\n",
              " 'есть',\n",
              " 'еще',\n",
              " 'ж',\n",
              " 'же',\n",
              " 'за',\n",
              " 'зачем',\n",
              " 'здесь',\n",
              " 'и',\n",
              " 'из',\n",
              " 'или',\n",
              " 'им',\n",
              " 'иногда',\n",
              " 'их',\n",
              " 'к',\n",
              " 'как',\n",
              " 'какая',\n",
              " 'какой',\n",
              " 'когда',\n",
              " 'конечно',\n",
              " 'кто',\n",
              " 'куда',\n",
              " 'ли',\n",
              " 'лучше',\n",
              " 'между',\n",
              " 'меня',\n",
              " 'мне',\n",
              " 'много',\n",
              " 'может',\n",
              " 'можно',\n",
              " 'мой',\n",
              " 'моя',\n",
              " 'мы',\n",
              " 'на',\n",
              " 'над',\n",
              " 'надо',\n",
              " 'наконец',\n",
              " 'нас',\n",
              " 'не',\n",
              " 'него',\n",
              " 'нее',\n",
              " 'ней',\n",
              " 'нельзя',\n",
              " 'нет',\n",
              " 'ни',\n",
              " 'нибудь',\n",
              " 'никогда',\n",
              " 'ним',\n",
              " 'них',\n",
              " 'ничего',\n",
              " 'но',\n",
              " 'ну',\n",
              " 'о',\n",
              " 'об',\n",
              " 'один',\n",
              " 'он',\n",
              " 'она',\n",
              " 'они',\n",
              " 'опять',\n",
              " 'от',\n",
              " 'перед',\n",
              " 'по',\n",
              " 'под',\n",
              " 'после',\n",
              " 'потом',\n",
              " 'потому',\n",
              " 'почти',\n",
              " 'при',\n",
              " 'про',\n",
              " 'раз',\n",
              " 'разве',\n",
              " 'с',\n",
              " 'сам',\n",
              " 'свою',\n",
              " 'себе',\n",
              " 'себя',\n",
              " 'сейчас',\n",
              " 'со',\n",
              " 'совсем',\n",
              " 'так',\n",
              " 'такой',\n",
              " 'там',\n",
              " 'тебя',\n",
              " 'тем',\n",
              " 'теперь',\n",
              " 'то',\n",
              " 'тогда',\n",
              " 'того',\n",
              " 'тоже',\n",
              " 'только',\n",
              " 'том',\n",
              " 'тот',\n",
              " 'три',\n",
              " 'тут',\n",
              " 'ты',\n",
              " 'у',\n",
              " 'уж',\n",
              " 'уже',\n",
              " 'хорошо',\n",
              " 'хоть',\n",
              " 'чего',\n",
              " 'чем',\n",
              " 'через',\n",
              " 'что',\n",
              " 'чтоб',\n",
              " 'чтобы',\n",
              " 'чуть',\n",
              " 'эти',\n",
              " 'этого',\n",
              " 'этой',\n",
              " 'этом',\n",
              " 'этот',\n",
              " 'эту',\n",
              " 'я'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faGJ7HulRnYh"
      },
      "source": [
        "c_text=[]\n",
        "jj = 0\n",
        "for i in df['comment']:\n",
        "  j = ' '.join([ w for w in [w for w in i.split() if not w in stop_words]])\n",
        "  c_text.append(j)\n",
        "df['comment']=c_text"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x5IG_ulqQL0"
      },
      "source": [
        "df.insert(0, \"Prz\", 1)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x77j3HxZTXDB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "9f154d81-1ed7-4b4c-d929-bdf7d3887163"
      },
      "source": [
        "df"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prz</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>На девятый день рождения дочка попросила новый...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Привет всем друзьям посетителям Отзовика!Смарт...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>За 10 000 рублей данный смартфон это оптимальн...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Привет, дорогой читатель(а пользователь) серви...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Искал телефон небольших размеров, удобно одно ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2584</th>\n",
              "      <td>1</td>\n",
              "      <td>Покупала телефон 7500, вышел продажи. Достоинс...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2585</th>\n",
              "      <td>1</td>\n",
              "      <td>Покупал новый 4300 рублей. В нём очень понрави...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2586</th>\n",
              "      <td>1</td>\n",
              "      <td>Пользуюсь смартфоном Fly IQ 441 года хочу сказ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2587</th>\n",
              "      <td>1</td>\n",
              "      <td>Всем привет. Этот телефон очень понравился сво...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2588</th>\n",
              "      <td>1</td>\n",
              "      <td>Получила данный телефон подарок мужа день рожд...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2519 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Prz                                            comment\n",
              "0       1  На девятый день рождения дочка попросила новый...\n",
              "1       1  Привет всем друзьям посетителям Отзовика!Смарт...\n",
              "2       1  За 10 000 рублей данный смартфон это оптимальн...\n",
              "3       1  Привет, дорогой читатель(а пользователь) серви...\n",
              "4       1  Искал телефон небольших размеров, удобно одно ...\n",
              "...   ...                                                ...\n",
              "2584    1  Покупала телефон 7500, вышел продажи. Достоинс...\n",
              "2585    1  Покупал новый 4300 рублей. В нём очень понрави...\n",
              "2586    1  Пользуюсь смартфоном Fly IQ 441 года хочу сказ...\n",
              "2587    1  Всем привет. Этот телефон очень понравился сво...\n",
              "2588    1  Получила данный телефон подарок мужа день рожд...\n",
              "\n",
              "[2519 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IF09WNdUi2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ecd7c68-76e0-45f7-c396-ba91382f0b2f"
      },
      "source": [
        "df['Prz'].value_counts()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    2519\n",
              "Name: Prz, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1zqCh-IUi2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba0b8a4-dad6-4cac-efc2-dbd8ee6fe432"
      },
      "source": [
        "possible_labels = df.Prz.unique()\n",
        "\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "label_dict"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo-wqvX8Ui2h"
      },
      "source": [
        "df['label'] = df.Prz"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8X5xlblUi2m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3b5043d3-4a1c-4f4b-c56b-17af864ca6d3"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prz</th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>На девятый день рождения дочка попросила новый...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Привет всем друзьям посетителям Отзовика!Смарт...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>За 10 000 рублей данный смартфон это оптимальн...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Привет, дорогой читатель(а пользователь) серви...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Искал телефон небольших размеров, удобно одно ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Prz                                            comment  label\n",
              "0    1  На девятый день рождения дочка попросила новый...      1\n",
              "1    1  Привет всем друзьям посетителям Отзовика!Смарт...      1\n",
              "2    1  За 10 000 рублей данный смартфон это оптимальн...      1\n",
              "3    1  Привет, дорогой читатель(а пользователь) серви...      1\n",
              "4    1  Искал телефон небольших размеров, удобно одно ...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOKXMljJUi2r"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
        "                                                  df.label.values, \n",
        "                                                  test_size=0.15, \n",
        "                                                  random_state=42, \n",
        "                                                  stratify=df.label.values)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5XPjmb0Ui27"
      },
      "source": [
        "df['data_type'] = ['not_set']*df.shape[0]\n",
        "\n",
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_val, 'data_type'] = 'val'"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O49Ii3RUi3C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "08d94cf0-cedc-49c1-de9a-595689c4b287"
      },
      "source": [
        "df.groupby(['Prz', 'label', 'data_type']).count()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Prz</th>\n",
              "      <th>label</th>\n",
              "      <th>data_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>train</th>\n",
              "      <td>2141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>378</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     comment\n",
              "Prz label data_type         \n",
              "1   1     train         2141\n",
              "          val            378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McYEERx9Ui3I"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
        "                                          do_lower_case=True)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH8yCwFVA0Y9",
        "outputId": "9873bebb-3bf9-4f44-8aef-b933d8c6a3d5"
      },
      "source": [
        " df[df.data_type=='train'].comment.values"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['На девятый день рождения дочка попросила новый телефон. Я сама стала задумываться том, купить современный (чем её старенький Alcatel 4034D) аппарат неё. Технику покупаю крайне редко особо разбираюсь. Поспрашивала знакомых какие недорогие варианты покупают (чтобы районе 10000). Как оказалось, основном берут Huawei Honor. Как понимаю производитель один. Или вычитала интернете Honor - это отдельный бред компании Huawei. В итоге решила доехать магазина \"DNS\" месте подобрать.Конечно телефону это имеет никакого отношения, просто хочется отметить. Обслуживали молча. Не посоветовать, уточнить, предложить. Вообще выражению лица понятно, интереса покупатели никакого представляем. Постояли, потоптались, ткнули пару моделей пальцем (ну умею выбирать). Остановились смартфоне Honor 8a prime стоимостью 9999 рублей.Вот чек покупки.С момента покупки написания отзыва прошло месяца. Хочу поделиться своими впечатлениями.Домой принесли такую картонную прямоугольную коробочку.Информация ней.-Из мукулатуры внутрь вложены брошюра краткое руководство пользователя.И гарантийный талон.-Из аксессуаров комплекте зарядное устройство, которое собирается блока питания кабеля Usb. Ни наушников, чехла, оказалось.А это смартфон Honor 8a prime.Ширинавысотатолщина 3.5мм156.2мм8.2мм. Диагональ экрана 6.08.Размер. Лично привыкла маленьким моделям, поэтому первое время непривычно держать руках. Для детской ручки считаю большеват. Дочка ничего, быстро освоилась. От старого телефона чехол подошёл. С приобретением нового проблем возникло, защитное стекло подобрали, ждём посылку. В наличие двух оттенках синий зелёный. Дочурка предпочла последний.Сразу задней стенке хотелось отметить, датчик отпечатка пальца. Также настроить функцию \"распознавание лица\". Мы пользуемся тем, другим.Немного ниже основной камеры расположен глазок вспышки, выполняет роль фонарика.Хоть наушники положили, разъём сверху имеется, наше время этого.Внизу разъём Usb динамики.Регулирование громкости кнопка питания понятно. Снимок экрана других наших телефонах путем одновременного нажатия клавиши уменьшения звука кнопки вкл/выкл.А дальше лично чайника интересный момент. Когда приехали домой стала пробовать открыть заднюю стенку, вставить привычке сим карту. А поддаётся. Мне магазине объяснили, специальный отсек сбоку есть. Уже стала изучать, осматривать, своим умом дошла.И коробочке волшебная железяка никто оповестил. Оказывается это ключик, который помогает открыть слот.Внутри место две симки карту памяти.Лично данная конструкция кажется надёжной. Несколько вытаскивали немного краешек погнулся.В папке \"настройки\" настроить телефон себя. Также, например, ознакомиться функцией \"NFC\" оплата касанием. Я такие штуки практикую, дочка более, поэтому нам надобности. С характеристиками телефона.Первоначальный вид экрана (воспроизвела выглядела главная страница), дочка её немного изменила, например, первую очередь поменяла обои.На смартфоне установлены разные приложения, такие \"Юла\", \"Honor магазин\" др. Дочка удалила (при длительном нажатие папку сразу появляется корзинка \"удалить\") загрузила свои.За памятью телефона легко следить.Основная камера 13Мп. За цену телефона хорошая.Для примера фото улице.ДомаЕсть функция вспышки. Мне понравилось то, чётко снимает мелкие детали. На моем телефоне такого сделаешь.Надеюсь, модераторы удалят это фото. Просто примера хочу показать качество съёмки 5Мп моем устройстве (слева) новом Honor 13Мп (справа). Разница ощущается.Фронтальная камера 8Мп. Снимает неплохо, устраивает.Единственное бывает долго фокусируется предмете.Работает шустро, глючит, виснет. Загрузки идут быстро. Игры отлично воспроизводит. Теперь те, которые поддерживались Alcatel работают проблем, дочка восторге. Громкость хорошая, слышимость тоже.По поводу зарядки. Заряда батареи хватает, играть заходить интернет (или находиться нем прям недолго), буквально сутки. Я считаю это слабовато. А играть смотреть видео, заряжать аппарат приходится раза сутки. Также фильмами. Воспроизводит отлично, весь экран, зависания, зарядка улетучивается хорошо. Есть режим энергосбережения ультра. И ещё медленно заряжается. По сравнению Alcatel это делает быстрее.В целом довольны смартфоном Honor 8a prime. За стоимость очень неплох. Плюсов взгляд гораздо больше, минусов. Достоинства:*Цена. *Камеры. *Память оперативная 3 Гб телефона 64Гб.*Звук.*Экран. *Возможность удалить приложения загрузить свои.*Работает андроиде. *Не глючит, зависает работе интернетом, социальными сетям, играми...*Отлично воспроизводит помех видео фильмы длительностью часа.*Кому важно поддержка NFC. *Также кому важно наличие датчика отпечатка пальца функция распознавания лица. *Прост управлении, быстро разобрались всем необходимым себя.Недостатки:*Зарядка.*Сомнительное качество слота симкарты карту памяти.*Теперь хочется поменять свой старенький телефон такой.',\n",
              "       'За 10 000 рублей данный смартфон это оптимальное решение, убедился собственном опыте. Прекрасно сбалансированные объемы оперативной 3Гб встроенной 64Гб памяти сочетании восьмиядерным процессором позволяют оптимально быстро выполнять подавляющее большинство поставленных задач. Данный смартфон греется любых нагрузках. Этот гаджет идеальным подарком ребенка. Очень быстрая разблокировка отпечатку пальца лицу. Достаточно хорошие камеры данной ценовой категории смартфонов, позволяющие делать хорошие фото. Заряд батарея держит сутки. Смартфоном полностью доволен. Рекомендую.',\n",
              "       \"Привет, дорогой читатель(а пользователь) сервиса отзывов Отзовик! Хочу поделиться своим мнением смартфоне Huawei Honor 8a prime.Данный телефон стоит 12500 рублей(это вместе защитным стеклом чехлом), вполне бюджетно. Вот выглядит:Хочу дополнительно сказать, экран яркий, впрочем, можете сами посмотреть:Поговорим характеристиках: диагональ экрана составляет 6.08'', разрешение 1560720, версия ОС Android 9.0 Pie.Объем оперативной памяти составляет 3 гб, встроенной 64 гб.Количество мп передней фронтальной камер 13 5 мп соответственно.Присутствует разблокировка отпечатку пальца.Более полную характеристику можете посмотреть Интернете.Задняя панель:Что хочется сказать смартфон? За вполне хорошую цену-вполне хорошие характеристики. Рекомендую.\",\n",
              "       ...,\n",
              "       'Пользуюсь смартфоном Fly IQ 441 года хочу сказать вполне доволен им. За всё это время разу подводил, глючит, работает исправно.Вполне быстрый многофункциональный аппаратИмеет дисплей диагональю 4.3 разрешением 480х800. Дисплей очень яркий, цвета насыщенные. Сенсор работает очень хорошо.Телефон поддерживает 2 сим карты, флеш карты 32 гигабайт, процессор 1000 МГц 2 ядерный(работает быстро), оперативка 512 мб.Имеет 5 мегапиксельную камеру светодиодной вспышкой возможностью снимать видео HD качестве. Есть фронтальная камера.В общем телефон качественный, функциональный недорогой главное очень стильно смотрится года эксплуатации корпусе отходит, крышка отваливается.Рекомендую!!!!',\n",
              "       'Всем привет. Этот телефон очень понравился своим качеством изготовления отличным (супер ) экраном, касается батареи всех, больших андроиде смартфонов - держит среднем половиной дня ( интересно само это очень неплохой результат двух симочного телефона аппарата таким большим большим экраном - это )В целом общем рекомендую, это отличный телефон неплохие деньги. Большой восторг появился покупки, очень долго ждал начнется начало продаж. Очень плохой особенностью телефона сборка, которая оставляет люфты двух недель использования',\n",
              "       'Получила данный телефон подарок мужа день рождения. В общем целом аппаратом довольна, небольшие погрешности, обо всем порядку.Предыдущий телефон FLY IQ245 перестал устраивать размерами экрана, часто приходилось выходить интернет. Собственно причине любимый решил \"побаловать\" новым телефончиком. Конечно, сравнению FLY IQ245 экран IQ441 Radiance значительно выигрывает размерах яркости, лежит, моей маленькой женской ручке - очень удобно. Порадовало наличие кнопки включения/выключения боковой панельке кнопками регулировки звука. Такое местоположение позволяет легкостью включать телефон ребенку, держа телефон одной рукой.Что касается звука, точнее громкости, FLY IQ245 выигрывает. Но, прочем, уровень громкости, который IQ441 Radiance, позволяет услышать звонок нахождении комнате. А, вот, разговаривать громкой связи, наличии посторонних шумов - собеседника можете услышать.Очень порадовало качество снимков основной камеры. Хотя объектив сразу фокусируется нужно подождать, вечернее время снимки получаются достойные. Ну, впрочем, мегапикселей тут, никак, 5 единиц. Интернет очень шустрый. Даже \"тяжелые\" сайты прогружаются очень быстро.Немного расстраивает момент, получается установить отдельные мелодии абонентов. Может это одна такая криворукая, факт остается фактом - играла общая мелодия всех, играет (хотя фотографии высвечиваются нужные).Еще минус, присущий многим смартфонам - слабенькая батарея. При активном использовании телефона, подзарядка нужна каждый день.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgxKhxScAk9d",
        "outputId": "25cda0b7-abba-4b3b-b620-7f0124ccde99"
      },
      "source": [
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='train'].comment.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=256, \n",
        "    return_tensors='pt'\n",
        ")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zXTuNlRUi3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e86b708d-4539-4e50-e904-5375bf89de4c"
      },
      "source": [
        "\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='val'].comment.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=256, \n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df[df.data_type=='train'].label.values,dtype=torch.long)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(df[df.data_type=='val'].label.values,dtype=torch.long)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbYIC45jUi3V"
      },
      "source": [
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNgco_p3Ui3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23dd3369-6b63-463f-9fd9-22d7935ac33e"
      },
      "source": [
        "len(dataset_train), len(dataset_val)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2141, 378)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGI4d3kAUi3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "50601d97b44947b6a53aeb8ae2c7a887",
            "d0377b4d9df745389f1ea3367c83e590",
            "d02cb564c1d9417f9dcce52114ecc860",
            "fa458a582fb346e2bd79ae195115fc08",
            "3f8f7927f41c46418573c04db2f71541",
            "a712f4a8955f4278bf6cd02b4fc00734",
            "b7d9a5c7661b4b35b744c2daf54aa40c",
            "e34279673ff84a408aa1bdcdc6833856",
            "cd3d0c69b7a7472c889e963be7d8e4b8",
            "3eaa1b4f228f41d6ae392c90449302ab",
            "63eedafd52df412ab3f8a8e9a7b3436b",
            "71f0bcb8bb2043aa84bc154beaca7998",
            "11a1ecf903054d75af3d8197c7940803",
            "30c09f1cb4bd4e918aa449bd6347ef74",
            "8a28702b7beb421dbf4188052eef5572",
            "502cf7a52ef94626bafd07ed88eda00b"
          ]
        },
        "outputId": "23395047-5830-44ba-c21a-9904d0287581"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                      num_labels=len(label_dict),\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50601d97b44947b6a53aeb8ae2c7a887",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd3d0c69b7a7472c889e963be7d8e4b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z1GPS9dBLEl"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 8"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RAvBVICUi3k"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, \n",
        "                              sampler=RandomSampler(dataset_train), \n",
        "                              batch_size=batch_size)\n",
        "\n",
        "dataloader_validation = DataLoader(dataset_val, \n",
        "                                   sampler=SequentialSampler(dataset_val), \n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbY3NOLlUi3p"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=1e-5, \n",
        "                  eps=1e-8)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiIT-j66Ui3t"
      },
      "source": [
        "epochs = 4\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=len(dataloader_train)*epochs)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q_wyON7Ui31"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjXuKSVTUi3-"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZHP90jAUi4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4040d984-588c-415f-d53f-a37da5bfc1de"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKRJFX1FUi4O"
      },
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in dataloader_val:\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BfFH-BPUi4U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445,
          "referenced_widgets": [
            "4cbab7727543441ea8efaff9b68ba826",
            "af5c0bb49fb64307b24c40d8b8671f9a",
            "9c7f93daadbe42599f7d8fe08c74f7c6",
            "d33baed97d7e4a44985fc80029f68a9d",
            "a54dce671a774f86ab55085ed6ec2145",
            "3028a4c9519445268db17e06bc2a9f34",
            "c4693d3926ef42969d43448180d4496b",
            "48237af598424b50a2e983dc6a25828c",
            "1b21991d701342bfb2451152f286b027",
            "5d2b9b74312443f0ba9072afc19b4b58",
            "8f6ae9157713429daa987da26bf53c58",
            "a427ad5f0f9e4af0a5e5716316eb0d52",
            "7260ab1645624d18bdc6ca63c7277ed7",
            "8955e608c0df44578a99fc7d6a6aafd1",
            "bbe88817865e41f3a7b59883c25041fe",
            "12b63526a3f0450f9c324ae50b636eaf"
          ]
        },
        "outputId": "1a1fa3b9-e00d-4204-96a5-868509ac2b52"
      },
      "source": [
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    loss_train_total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        model.zero_grad()\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }       \n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "         \n",
        "        \n",
        "    torch.save(model.state_dict(), f'finetuned_BERT_epoch_{epoch}.model')\n",
        "        \n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cbab7727543441ea8efaff9b68ba826",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b21991d701342bfb2451152f286b027",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=268.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-9306225bb55a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss_train_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Long but expected Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmh22GUJUi4Y",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "865c5727-9b23-4598-f4db-8ae6ea046f04"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                      num_labels=len(label_dict),\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "\n",
        "model.to('cuda')"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpvJHMI-Ui4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "d3ded9e5-6bfc-4125-9eb0-b4ec2923d5ce"
      },
      "source": [
        "model.load_state_dict(torch.load('finetuned_BERT_epoch_3.model', map_location=torch.device('cpu')))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-1d0685fe2566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'finetuned_BERT_epoch_3.model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'finetuned_BERT_epoch_3.model'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rpPVmH-Ui4p"
      },
      "source": [
        "_, predictions, true_vals = evaluate(dataloader_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib3f5EueKECd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4489e92d-4250-439e-9461-7ecde9aebc1e"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.701269  ,  1.265477  , -1.0989971 , -2.1158788 , -2.30888   ,\n",
              "        -2.0789335 ],\n",
              "       [ 6.775178  , -0.08133557, -1.3402019 , -1.8453351 , -1.5773239 ,\n",
              "        -1.409198  ],\n",
              "       [ 6.8711667 ,  0.27579504, -1.3199737 , -1.9986652 , -1.7535454 ,\n",
              "        -1.5519205 ],\n",
              "       ...,\n",
              "       [-2.530412  , -2.0244465 , -1.1328572 ,  0.34031317,  2.2881658 ,\n",
              "         3.544518  ],\n",
              "       [ 0.9167181 ,  2.4891872 ,  2.6774354 , -0.08066647, -2.762556  ,\n",
              "        -4.28428   ],\n",
              "       [-1.1291463 ,  2.0318134 ,  2.7955718 ,  1.5517545 , -2.327366  ,\n",
              "        -3.8731647 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Zwxo-EhUi4x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ae38be-c5db-48de-bddb-8a11dae1ab61"
      },
      "source": [
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: 0.0\n",
            "Accuracy: 2208/2449\n",
            "\n",
            "Class: 4.0\n",
            "Accuracy: 571/1002\n",
            "\n",
            "Class: 1.0\n",
            "Accuracy: 197/611\n",
            "\n",
            "Class: 3.0\n",
            "Accuracy: 495/768\n",
            "\n",
            "Class: 2.0\n",
            "Accuracy: 122/289\n",
            "\n",
            "Class: 5.0\n",
            "Accuracy: 28/68\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRklVH8bUi47"
      },
      "source": [
        "def predicti(dataloader_test):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions = []\n",
        "    \n",
        "    for batch in dataloader_test:\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "        # loss = outputs[0]\n",
        "        logits = outputs[0]\n",
        "        # loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        # label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        # true_vals.append(label_ids)\n",
        "    \n",
        "    # loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    # true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfD1UZjIIBnx"
      },
      "source": [
        "import csv\n",
        "def read_test(path=\"test.csv\"):\n",
        "    texts = []\n",
        "    # stop_words = set(stopwords.words('english')) \n",
        "    # lemmatizer = WordNetLemmatizer()\n",
        "    # uuids = []\n",
        "    with open(path, newline='') as csvfile:\n",
        "        reader = csv.reader(csvfile, delimiter=',', )\n",
        "        # next(reader)\n",
        "        for row in reader:\n",
        "            text = row\n",
        "            text = ' '.join([lemmatizer.lemmatize(w) for w in [w for w in text[0].split() if not w in stop_words]])\n",
        "            # uuids.append(uuid)\n",
        "            texts.append(text)\n",
        "    return (texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Klj6xOqY-QE"
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "OzzDMUwF_bjr",
        "outputId": "879d042f-5527-402e-df1d-b420882078f6"
      },
      "source": [
        "test=read_test(\"dataset_316011_2.txt\")\n",
        "test=np.ravel(test)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-becf9735ba73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset_316011_2.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'read_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPo_dx4X_Spc",
        "outputId": "2d09c22a-1ddb-4b64-dfee-7c799b4f1681"
      },
      "source": [
        "encoded_data_test = tokenizer.batch_encode_plus(\n",
        "    test, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=256, \n",
        "    return_tensors='pt'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1NYmxxuJCNZ"
      },
      "source": [
        "input_ids_test = encoded_data_test['input_ids']\n",
        "attention_masks_test = encoded_data_test['attention_mask']\n",
        "\n",
        "dataset_test = TensorDataset(input_ids_test, attention_masks_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSBMy6PIJcPv"
      },
      "source": [
        "dataloader_test = DataLoader(dataset_test, \n",
        "                                   sampler=SequentialSampler(dataset_test), \n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBpvYpVUBSgA"
      },
      "source": [
        "device='cuda'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seKtwpaQJqXr"
      },
      "source": [
        "predictions = predicti(dataloader_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBxOOnNdJudl"
      },
      "source": [
        "x=np.argmax(predictions, axis=1).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbD_sioeNvU-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3efcc12-bd7d-423d-d7a0-ae9374bc4c6a"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 3, 0, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ1U7u5pNJN6"
      },
      "source": [
        "np.savetxt('test.txt', x, delimiter=',',fmt='%s')   # X is an array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f73Y70eINXrH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}